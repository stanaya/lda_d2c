\documentclass[uplatex,dvipdfmx,fleqn]{jsarticle}
\和暦
\usepackage[top=25truemm,bottom=25truemm,left=25truemm,right=25truemm]{geometry}
\usepackage[dvipdfmx]{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage[bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc]{hyperref}
\usepackage{pxjahyper}
\hypersetup{pdftitle={lightlda.sh},pdfauthor={木村　健},
  pdfkeywords={upTeX,upLaTeX,LDA,NIPS,ja.text8,20newsgroups}}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\begin{document}

\title{\huge lightlda.sh}
\author{木村　健}
\date{\today}
\maketitle


\section{このドキュメントについて}
本ドキュメントは持橋先生からご提供いただいた、lightldaを
簡単に使うlightlda.shについて、既存のデータセットで試したので
その報告をする。

なお分類結果についてはS3, BitBucket に置く予定なので参照して
いただきたい。

\section{lightlda\protect\cite{lightlda}とは}
非常に高速にLDAを行うプログラムである（詳細はウェブページを。。。）。
ただ入出力の形式が独自で、少し（lda.pyを使っていた身からすると）使いずらい。
そこで、lightlda.shという一連のスクリプトを使うと、なんと、
ほぼlda.pyのインターフェイスでLDAを行うことができる（素晴らしい）。

今回はそのlightlda.shに対して新しいPythonファイルの追加と、
lightlda.sh(bashファイル)の追加を行い、visLDA.pyと同様の
結果を得ることに成功した。

またLDAの各トピックごとのソーティング（上下関係）も二種類の尺度を
用いて分類できたのでこれを紹介する。

\section{preLDAJSON.py}
以前作ったファイルだが、All About コーパスのJSON形式（AA2.jsonという巨大なファイル）
からlda.pyに必要なsvmファイルと単語を列挙したwordsファイルを抽出する。

各記事には記事番号が付与されている。また記事のページごとにその下の階層でページ番号が付与されている。
各ページは見出しとテキストの集合からなり、今回はページ単位で一つのドキュメントとして
svmファイルを生成した。

\section{lightlda2pickle.py}
lightlda.shの実行結果取り出しから直接visLDA.pyのようなcsv結果ファイルを
取り出せないことがわかり、lightlda.shの最終段階にpickleファイルを生成する
lightlda2pickle.pyファイルを新しく追加してより多くの情報を取り出すようにした。

$k$ をトピックのid、$w$を単語id、$d$をドキュメントidとする。
paramファイルには、$alpha$, $beta$, $iterations$, $topics$ が入っている。

lightlda2pickle.py の生成物はpickle4.gzというgzipされたPython Pickle file (protocol = 4)
である。

中に入っているオブジェクトはdict一つだけであり、それぞれのkeyとcontentは次の通り。
今dictオブジェクトをmodelとして参照しているとすると、
　
\begin{itemize}
\item model['alpha'] = $alpha$ (single value)
\item model[‘topics’] = $topics$ (single value)
\item model[‘C(w)’] = 単語の頻度$C(w)$ (長さ=$nlex$).
\item	model[ ’N’] = $N$ (total occurence).
\item model[‘nlex'] = $nlex$ (語彙数).
\item model[’C(k)’] = それぞれのtopicsの頻度$C(k)$
\item	model[’P(w$|$k)’] =  キー(w,k)を持つdict: dictの中身は$P(w|k)$
\item model[’P(w$|$k)/P(w)’] = キー(w,k)を持つdict: dictの中身は$\displaystyle\frac{P(w|k)}{P(w)}$
\end{itemize}

最後の二つがvisualizeに使われる確率で、それぞれ次のように（便宜上）呼ぶことにする。

\begin{itemize}
\item	$P(w|k)$: normal probability
\item $\displaystyle\frac{P(w|k)}{P(w)}$: maniac probability
\end{itemize}

\begin{eqnarray}
P(w|k) & = & \frac{P(k|w)P(w)}{P(k)}. \\
\frac{p(w|k)}{P(w)} & = & P(k|w)P(w). \\
P(k|w) & = & \frac{C(k,w)}{C(w)}. \\
C(w) & = & \frac{C(k,w)}{P(k|w)} -> normalized -> P(w). \\
\mbox{or}\/ C(w) & = & \sum_k C(k,w) -> normalized -> p(w). \\ 
\mbox{or}\/ P(w|k) & = & \frac{C(w,k)}{C(k)}.\\
\end{eqnarray}

\section{結果}

結果をレポジトリのtopicsフォルダに置いたので参照して欲しい。
特にmaniacの方は「マニアック（笑）」と思える内容の単語が上に来ていることがわかる。

\section{lightlda, lightlda.sh の変更箇所}

\subsection{lightldaの変更箇所}
~/lightlda/multiverso (~/lightlda を展開フォルダとしたとき) のMakefile を変更（Ubuntu 18.04).

\begin{verbatim}
diff --git a/Makefile b/Makefile
index c7bf4f5..e42d214 100644
--- a/Makefile
+++ b/Makefile
@@ -18,7 +18,7 @@ THIRD_PARTY_LIB = $(THIRD_PARTY)/lib

 INC_FLAGS = -I$(HEADERS_DIR)
 INC_FLAGS += -I$(THIRD_PARTY_INC)
-LD_FLAGS = -L$(THIRD_PARTY_LIB) -lzmq -lmpich -lmpl
+LD_FLAGS = -L$(THIRD_PARTY_LIB) -lzmq -lmpich -lmpl -lpthread

 LIB_SRC_DIR = $(PROJECT)/src/multiverso
 SERVER_SRC_DIR = $(PROJECT)/src/multiverso_server
\end{verbatim}

あとLD\_LIBRARY\_PATHに　zmqのライブラリが見えるようにする必要があったと思う（うろ覚え）。

\subsection{lightlda.shの変更箇所}
シェバングを/bin/shから/bin/bashに。
最後で、

\begin{verbatim}
python3 ../lightlda2pickle.py .
\end{verbatim}
を追加。

全体的にlightlda2pickle.pyは追加。


\begin{thebibliography}{99}
  \bibitem{murphy} Kevin P. Murphy: Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series) The MIT Press, 2012.
  \bibitem{blei} Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.: Latent Dirichlet Allocation,
J. Mach. Learn. Res. 3/1, volume 3, 2003.
  \bibitem{griffiths} Thomas L. Griffiths, Mark Steyvers.: Finding Scientific Topics. PNAS (101) pp. 5228-5235, 2004.
  \bibitem{lightlda} LightLDA: Big Topic Models on Modest Computer Clusters: Yuan, Jinhui and Gao, Fei and Ho, Qirong and Dai, Wei and Wei, Jinliang and Zheng, Xun and Xing, Eric Po and Liu, Tie-Yan and Ma, Wei-Ying,
  Proceedings of the 24th International Conference on World Wide Web, pp.1351--1361,2015.
\end{thebibliography}
\end{document}
